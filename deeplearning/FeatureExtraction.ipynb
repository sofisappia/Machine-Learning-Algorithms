{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as spio\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib as mpl\n",
    "from os import path\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import socket\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from wyrm.types import Data\n",
    "\n",
    "from wyrm import plot\n",
    "#plot.beautify()\n",
    "from wyrm.types import Data\n",
    "from wyrm import processing as proc\n",
    "\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_A = '../../BCI_Comp_III_Wads_2004/data/Subject_A_Train.mat'\n",
    "TRAIN_B = '../../BCI_Comp_III_Wads_2004/data/Subject_B_Train.mat'\n",
    "\n",
    "TEST_A = '../../BCI_Comp_III_Wads_2004/data/Subject_A_Test.mat'\n",
    "TEST_B = '../../BCI_Comp_III_Wads_2004/data/Subject_B_Test.mat'\n",
    "\n",
    "TRUE_LABELS_A = 'WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'\n",
    "TRUE_LABELS_B = 'MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR'\n",
    "\n",
    "MATRIX = ['abcdef',\n",
    "          'ghijkl',\n",
    "          'mnopqr',\n",
    "          'stuvwx',\n",
    "          'yz1234',\n",
    "          '56789_']\n",
    "\n",
    "MARKER_DEF_TRAIN = {'target': ['target'], 'nontarget': ['nontarget']}\n",
    "MARKER_DEF_TEST = {'flashing': ['flashing']}\n",
    "\n",
    "SEG_IVAL = [0, 700]\n",
    "\n",
    "def load_bci_data(filename):\n",
    "    \"\"\"Load the BCI Competition III Data Set 2.\n",
    "    This method loads the data set and converts it into Wyrm's ``Data``\n",
    "    format. Before you use it, you have to download the data set in\n",
    "    Matlab format and unpack it. The directory with the extracted files\n",
    "    must contain the ``Subject_*.mat``- and the ``eloc64.txt`` files.\n",
    "    .. note::\n",
    "        If you need the true labels of the test sets, you'll have to\n",
    "        download them separately from\n",
    "        http://bbci.de/competition/iii/results/index.html#labels\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        The path to the matlab file to load\n",
    "    Returns\n",
    "    -------\n",
    "    cnt : continuous `Data` object\n",
    "    Examples\n",
    "    --------\n",
    "    >>> dat = load_bcicomp3_ds2('/home/foo/data/Subject_A_Train.mat')\n",
    "    \"\"\"\n",
    "    STIMULUS_CODE = {\n",
    "        0 : \"blankMatrix\",\n",
    "        # cols from left to right\n",
    "        1 : \"agmsy5\",\n",
    "        2 : \"bhntz6\",\n",
    "        3 : \"ciou17\",\n",
    "        4 : \"djpv28\",\n",
    "        5 : \"ekqw39\",\n",
    "        6 : \"flrx4_\",\n",
    "        # rows from top to bottom\n",
    "        7 : \"abcdef\",\n",
    "        8 : \"ghijkl\",\n",
    "        9 : \"mnopqr\",\n",
    "        10: \"stuvwx\",\n",
    "        11: \"yz1234\",\n",
    "        12: \"56789_\"\n",
    "        }\n",
    "\n",
    "    # load the matlab data\n",
    "    data_mat = loadmat(filename)\n",
    "    # load the channel names (the same for all datasets\n",
    "    eloc_file = path.sep.join([path.dirname(filename), 'eloc64.txt'])\n",
    "    with open(eloc_file) as fh:\n",
    "        data = fh.read()\n",
    "    channels = []\n",
    "    for line in data.splitlines():\n",
    "        if line:\n",
    "            chan = line.split()[-1]\n",
    "            chan = chan.replace('.', '')\n",
    "            channels.append(chan)\n",
    "    # fix the channel names, some letters have the wrong capitalization\n",
    "    for i, s in enumerate(channels):\n",
    "        s2 = s.upper()\n",
    "        s2 = s2.replace('Z', 'z')\n",
    "        s2 = s2.replace('FP', 'Fp')\n",
    "        channels[i] = s2\n",
    "    # The signal is recorded with 64 channels, bandpass filtered\n",
    "    # 0.1-60Hz and digitized at 240Hz. The format is Character Epoch x\n",
    "    # Samples x Channels\n",
    "    data = data_mat['Signal']\n",
    "    data = data.astype('double')\n",
    "    # For each sample: 1 if a row/colum was flashed, 0 otherwise\n",
    "    flashing = data_mat['Flashing'].reshape(-1)\n",
    "    #flashing = np.flatnonzero((np.diff(a) == 1)) + 1\n",
    "    ##Creates an array where only the initial intensifications of each series appear\n",
    "    tmp = []\n",
    "    for i, _ in enumerate(flashing):\n",
    "        if i == 0:\n",
    "            tmp.append(flashing[i])\n",
    "            continue\n",
    "        if flashing[i] == flashing[i-1] == 1:\n",
    "            tmp.append(0)\n",
    "            continue\n",
    "        tmp.append(flashing[i])\n",
    "    flashing = np.array(tmp)\n",
    "    # For each sample: 0 when no row/colum was intensified,\n",
    "    # 1..6 for intensified columns, 7..12 for intensified rows\n",
    "    stimulus_code = data_mat['StimulusCode'].reshape(-1)\n",
    "    stimulus_code = stimulus_code[flashing == 1]\n",
    "    # 0 if no row/col was intensified or the intensified did not contain\n",
    "    # the target character, 1 otherwise\n",
    "    stimulus_type = data_mat.get('StimulusType', np.array([])).reshape(-1)\n",
    "    # The target characters\n",
    "    target_chars = data_mat.get('TargetChar', np.array([])).reshape(-1)\n",
    "    fs = 240\n",
    "    data = data.reshape(-1, 64)\n",
    "    timeaxis = np.linspace(0, data.shape[0] / fs * 1000, data.shape[0], endpoint=False)\n",
    "    dat = Data(data=data, axes=[timeaxis, channels], names=['time', 'channel'], units=['ms', '#'])\n",
    "    dat.fs = fs\n",
    "    # preparing the markers\n",
    "    target_mask = np.logical_and((flashing == 1), (stimulus_type == 1)) if len(stimulus_type) > 0 else []\n",
    "    nontarget_mask = np.logical_and((flashing == 1), (stimulus_type == 0)) if len(stimulus_type) > 0 else []\n",
    "    flashing = (flashing == 1)\n",
    "    flashing = [[i, 'flashing'] for i in timeaxis[flashing]]\n",
    "    targets = [[i, 'target'] for i in timeaxis[target_mask]]\n",
    "    nontargets = [[i, 'nontarget'] for i in timeaxis[nontarget_mask]]\n",
    "    dat.stimulus_code = stimulus_code[:]\n",
    "    stim = []\n",
    "    for i,_ in enumerate(flashing):\n",
    "        stim.append([flashing[i][0], STIMULUS_CODE[stimulus_code[i]]])\n",
    "    stimulus_code = stim\n",
    "    #stimulus_code = zip([t for t, _ in flashing], [STIMULUS_CODE[i] for i in stimulus_code])\n",
    "    #Raises error \"TypeError: '<' not supported between instances of 'tuple' and 'list'\" when calling sort() \n",
    "    #stimulus_code =[[t for t,_ in flashing], [STIMULUS_CODE[i] for i in stimulus_code]]\n",
    "    #print(type(stimulus_code), type(flashing), type(targets), type(nontargets))\n",
    "    markers = flashing[:]\n",
    "    markers.extend(targets)\n",
    "    markers.extend(nontargets)\n",
    "    markers.extend(stimulus_code)\n",
    "    markers.sort()\n",
    "    dat.markers = markers[:]\n",
    "    return dat\n",
    "\n",
    "\n",
    "def preprocessing_simple(dat, MRK_DEF, *args, **kwargs):\n",
    "    \"\"\"Simple preprocessing that reaches 97% accuracy.\n",
    "    \"\"\"\n",
    "    fs_n = dat.fs / 2\n",
    "    b, a = proc.signal.butter(5, [10 / fs_n], btype='low')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "   \n",
    "    dat = proc.subsample(dat, 20)\n",
    "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
    "    fv = proc.create_feature_vectors(epo)\n",
    "    return fv, epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:wyrm.processing:Subsampling led to loss of 6 samples, in an online setting consider using a BlockBuffer with a buffer size of a multiple of 12 samples.\n",
      "WARNING:wyrm.processing:Subsampling led to loss of 6 samples, in an online setting consider using a BlockBuffer with a buffer size of a multiple of 12 samples.\n"
     ]
    }
   ],
   "source": [
    "dat_train_A = load_bci_data(TRAIN_A)\n",
    "fv_train_A, epo_A = preprocessing_simple(dat_train_A, MARKER_DEF_TRAIN, SEG_IVAL)\n",
    "\n",
    "# Subject B\n",
    "dat_train_B = load_bci_data(TRAIN_B)\n",
    "fv_train_B, epo_B = preprocessing_simple(dat_train_B, MARKER_DEF_TRAIN, SEG_IVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 14, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epo_A.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
